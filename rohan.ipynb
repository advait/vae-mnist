{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebbbfb60-8c17-46fb-a69e-60d1fefd454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 12:44:25.595178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 12:44:26.593856: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/advait/miniconda3/envs/rohan/lib/python3.9/site-packages/nvidia/cublas/lib/:/home/advait/miniconda3/envs/rohan/lib/python3.9/site-packages/nvidia/cublas/lib/::/home/advait/miniconda3/envs/rohan/lib/\n",
      "2023-01-06 12:44:26.593961: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/advait/miniconda3/envs/rohan/lib/python3.9/site-packages/nvidia/cublas/lib/:/home/advait/miniconda3/envs/rohan/lib/python3.9/site-packages/nvidia/cublas/lib/::/home/advait/miniconda3/envs/rohan/lib/\n",
      "2023-01-06 12:44:26.593966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # plotting library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import io\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import einops\n",
    "from einops.layers.torch import Rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfe93ed-c35a-48f1-9b8f-84307f09cddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Selected device: {device}\")\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "data_dir = \"dataset\"\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "train_transform = test_transform = transforms.ToTensor()\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m = len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m - m * 0.2), int(m * 0.2)])\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f486caf2-f599-499c-ba75-66d17f2fa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.main_block = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=2, padding=0),  # 1x28x28 -> 32x12x12\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=0),  # 32x12x12 -> 64x4x4\n",
    "            nn.ReLU(),\n",
    "            Rearrange(\"b c h w -> b (c h w)\"),\n",
    "            nn.Linear(64 * 4 * 4, 64 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64 * 4 * 4, 64 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.LazyLinear(latent_dims),\n",
    "        )\n",
    "        self.log_var = nn.Sequential(\n",
    "            nn.LazyLinear(latent_dims),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def sample(self, mu, log_var):\n",
    "        std = log_var.mul(0.5).exp_()\n",
    "        esp = torch.randn(*std.size()).to(device)\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = self.main_block(x)\n",
    "        mu = self.mu(x)\n",
    "        log_var = self.log_var(x)\n",
    "        z = self.sample(mu, log_var)\n",
    "        return z, mu, log_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.main_block = nn.Sequential(\n",
    "            nn.Linear(latent_dims, 64 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64 * 4 * 4, 64 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            Rearrange(\"b (c h w) -> b c h w\", c=64, h=4, w=4),\n",
    "            nn.ConvTranspose2d(\n",
    "                64, 32, 5, stride=2, output_padding=1\n",
    "            ),  # 64x4x4 -> 32x12x12\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                32, 1, 5, stride=2, output_padding=1\n",
    "            ),  # 32x12x12 -> 1x28x28\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        return self.main_block(x)\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = Encoder(latent_dims)\n",
    "        self.decoder = Decoder(latent_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        z, mu, log_var = self.encoder(x)\n",
    "        return self.decoder(z), z, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03bb4955-2877-467f-8e92-cffdef1e2dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/advait/miniconda3/envs/rohan/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VariationalAutoencoder(\n",
       "  (encoder): Encoder(\n",
       "    (main_block): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Rearrange('b c h w -> b (c h w)')\n",
       "      (5): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (8): ReLU()\n",
       "    )\n",
       "    (mu): Sequential(\n",
       "      (0): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "    )\n",
       "    (log_var): Sequential(\n",
       "      (0): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (main_block): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Rearrange('b (c h w) -> b c h w', c=64, h=4, w=4)\n",
       "      (5): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2), output_padding=(1, 1))\n",
       "      (6): ReLU()\n",
       "      (7): ConvTranspose2d(32, 1, kernel_size=(5, 5), stride=(2, 2), output_padding=(1, 1))\n",
       "      (8): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "latent_dims = 10\n",
    "lr = 1e-3\n",
    "\n",
    "vae = VariationalAutoencoder(latent_dims=latent_dims)\n",
    "optim = torch.optim.Adam(vae.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "vae.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87cc1b3-bdf0-4827-9c39-3e4c97721f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x_hat, x, mu, log_var):\n",
    "    bce = F.binary_cross_entropy(x_hat, x, reduction=\"sum\")\n",
    "    kl = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return bce + kl\n",
    "\n",
    "\n",
    "def train_epoch(vae, device, dataloader, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    vae.train()\n",
    "    train_loss = 0.0\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for x, _ in dataloader:\n",
    "        # Move tensor to the proper device\n",
    "        x = x.to(device)\n",
    "        x_hat, _, mu, log_var = vae(x)\n",
    "        loss = loss_function(x_hat, x, mu, log_var)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def test_epoch(vae, device, dataloader):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    vae.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():  # No need to track the gradients\n",
    "        for x, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            x = x.to(device)\n",
    "            x_hat, _, mu, log_var = vae(x)\n",
    "            loss = loss_function(x_hat, x, mu, log_var)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def plot_ae_outputs(vae, n=10):\n",
    "    plt.figure(figsize=(16, 4.5))\n",
    "    targets = test_dataset.targets.numpy()\n",
    "    t_idx = {i: np.where(targets == i)[0][0] for i in range(n)}\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        img = test_dataset[t_idx[i]][0].unsqueeze(0).to(device)\n",
    "        vae.eval()\n",
    "        with torch.no_grad():\n",
    "            x_hat, _, _, _ = vae(img)\n",
    "        plt.imshow(img.cpu().squeeze().numpy(), cmap=\"gist_gray\")\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n // 2:\n",
    "            ax.set_title(\"Original images\")\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(x_hat.cpu().squeeze().numpy(), cmap=\"gist_gray\")\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n // 2:\n",
    "            ax.set_title(\"Reconstructed images\")\n",
    "    return plt.gcf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ab4870-595b-4262-b89f-2da037044415",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "\n",
      " EPOCH 1/500 \t train loss 138.552 \t val loss 138.983\n",
      "\n",
      " EPOCH 2/500 \t train loss 138.409 \t val loss 138.573\n",
      "\n",
      " EPOCH 3/500 \t train loss 138.329 \t val loss 138.751\n",
      "\n",
      " EPOCH 4/500 \t train loss 138.300 \t val loss 138.829\n",
      "\n",
      " EPOCH 5/500 \t train loss 138.181 \t val loss 138.697\n",
      "\n",
      " EPOCH 6/500 \t train loss 138.048 \t val loss 138.284\n",
      "\n",
      " EPOCH 7/500 \t train loss 138.019 \t val loss 138.537\n",
      "\n",
      " EPOCH 8/500 \t train loss 138.001 \t val loss 138.458\n",
      "\n",
      " EPOCH 9/500 \t train loss 137.796 \t val loss 138.672\n",
      "\n",
      " EPOCH 10/500 \t train loss 137.862 \t val loss 138.502\n",
      "Validation loss is no longer shrinking. Quitting early.\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 500\n",
    "val_losses = []\n",
    "\n",
    "print(\"Beginning training\")\n",
    "writer.add_hparams({\n",
    "    \"latent_dims\": \"int\",\n",
    "    \"lr\": \"float\",\n",
    "    \"batch_size\": \"int\",\n",
    "}, {\n",
    "    \"latent_dims\": latent_dims,\n",
    "    \"lr\": lr,\n",
    "    \"batch_size\": batch_size,\n",
    "})\n",
    "\n",
    "fig = plot_ae_outputs(vae, n=10)\n",
    "writer.add_figure(\"VAE Output\", fig, 0)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = train_epoch(vae, device, train_loader, optim)\n",
    "    val_loss = test_epoch(vae, device, valid_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "    fig = plot_ae_outputs(vae, n=10)\n",
    "    writer.add_figure(\"VAE Output\", fig, epoch)\n",
    "\n",
    "    writer.flush()\n",
    "\n",
    "    print(\n",
    "        \"\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}\".format(\n",
    "            epoch + 1, max_epochs, train_loss, val_loss\n",
    "        )\n",
    "    )\n",
    "    if len(val_losses) >= 5 and val_losses[-5] < val_loss:\n",
    "        print(\"Validation loss is no longer shrinking. Quitting early.\")\n",
    "        break\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b7392-5b70-4d4f-a437-03b1fa8ac6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random samples from the latent space\n",
    "\n",
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    # sample latent vectors from the normal distribution\n",
    "    latent = torch.randn(100, latent_dims, device=device)\n",
    "\n",
    "    # reconstruct images from the latent vectors\n",
    "    img_recon = vae.decoder(latent)\n",
    "    img_recon = img_recon.cpu()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 8.5))\n",
    "    show_image(torchvision.utils.make_grid(img_recon.data, 10, 5))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46b43c-97d2-487e-bb81-020e7689a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average z and std of a bunch of zeroes\n",
    "\n",
    "zeroes = [\n",
    "    train_dataset.data[i] for i, label in enumerate(train_dataset.targets) if label == 0\n",
    "]\n",
    "zeroes = zeroes[:100]\n",
    "zeroes = einops.rearrange(torch.stack(zeroes).type(torch.float32), \"b h w -> b 1 h w\")\n",
    "zeroes.to(device)\n",
    "with torch.no_grad():\n",
    "    vae.eval()\n",
    "    _, mu, log_var = vae.encoder(zeroes)\n",
    "\n",
    "    # Average mu and log_var for zeroes in our dataset\n",
    "    mu_avg = einops.reduce(mu, \"b mu -> mu\", \"mean\").cpu()\n",
    "    log_var_avg = einops.reduce(log_var, \"b l -> l\", \"mean\").cpu()\n",
    "    std_avg = log_var.cpu().mul(0.5).exp_()\n",
    "\n",
    "    # Generate a bunch of zeroes from latent sampling\n",
    "    esp = torch.randn(100, latent_dims, dtype=torch.float32)\n",
    "    z = (esp.mul(std_avg).add(esp)).to(device)\n",
    "\n",
    "    img_recon = vae.decoder(z)\n",
    "    img_recon = img_recon.cpu()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 8.5))\n",
    "    show_image(torchvision.utils.make_grid(img_recon.data, 10, 5))\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('rohan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "55cd91629504115e3153f8b8a98f9b017d710a76b967e95927994fbaa1653cdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
